{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "# import libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train = pd.read_csv(\"//home//mgwarada//Desktop//Ruvimbo//application_train.csv\")\n",
    "#application_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colNullCnt = []\n",
    "#for z in range(len(application_train.columns)):\n",
    "#    colNullCnt.append([application_train.columns[z], sum(pd.isnull(application_train[application_train.columns[z]]))])\n",
    "    \n",
    "#colNullCnt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#application_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add debt to income ratio a key measure of capacity in credit risk management\n",
    "application_train['DEBT_TO_INCOME'] = application_train['AMT_CREDIT']/ application_train['AMT_INCOME_TOTAL']\n",
    "#application_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1716428, 17)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau = pd.read_csv(\"/home/mgwarada/Desktop/Ruvimbo/bureau.csv\")\n",
    "\n",
    "\n",
    "bureau.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1716428 entries, 0 to 1716427\n",
      "Data columns (total 17 columns):\n",
      "SK_ID_CURR                int64\n",
      "SK_ID_BUREAU              int64\n",
      "CREDIT_ACTIVE             object\n",
      "CREDIT_CURRENCY           object\n",
      "DAYS_CREDIT               int64\n",
      "CREDIT_DAY_OVERDUE        int64\n",
      "DAYS_CREDIT_ENDDATE       float64\n",
      "DAYS_ENDDATE_FACT         float64\n",
      "AMT_CREDIT_MAX_OVERDUE    float64\n",
      "CNT_CREDIT_PROLONG        int64\n",
      "AMT_CREDIT_SUM            float64\n",
      "AMT_CREDIT_SUM_DEBT       float64\n",
      "AMT_CREDIT_SUM_LIMIT      float64\n",
      "AMT_CREDIT_SUM_OVERDUE    float64\n",
      "CREDIT_TYPE               object\n",
      "DAYS_CREDIT_UPDATE        int64\n",
      "AMT_ANNUITY               float64\n",
      "dtypes: float64(8), int64(6), object(3)\n",
      "memory usage: 222.6+ MB\n"
     ]
    }
   ],
   "source": [
    "bureau.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bureau data has duplicated customer ids, aggregating variables would help when we mere data\n",
    "\n",
    "bureau_grouped = bureau.drop(['SK_ID_BUREAU'],axis=1).groupby('SK_ID_CURR', as_index = False).agg(['count', 'mean','max' ,'sum']).reset_index()\n",
    "#bureau_grouped.head()\n",
    "bureau_grouped.name= 'bureau_grouped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to change code ASAP\n",
    "\n",
    "def format_columns(df):\n",
    "    columns = ['SK_ID_CURR']\n",
    "\n",
    "# Iterate through the variables names\n",
    "    for var in df.columns.levels[0]:\n",
    "    # Skip the id name\n",
    "        if var != 'SK_ID_CURR':\n",
    "        \n",
    "        # Iterate through the stat names\n",
    "           for stat in df.columns.levels[1][:-1]:\n",
    "            # Make a new column name for the variable and stat\n",
    "                columns.append(str(df.name) + \" \" + var + \" \" +str(stat))\n",
    "    return columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = format_columns(bureau_grouped)\n",
    "bureau_grouped.columns= columns \n",
    "#bureau_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df for active loans for each client\n",
    "#active_loans = bureau[bureau['CREDIT_ACTIVE']=='Active']\n",
    "#active_loans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#active_loans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#active_grouped = active_loans.drop(['SK_ID_BUREAU'],axis=1).groupby('SK_ID_CURR', as_index = False).agg(['count', 'mean','max', 'sum']).reset_index()\n",
    "#active_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#active_grouped.columns = columns \n",
    "#active_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance = pd.read_csv(\"//home/mgwarada/Desktop/Ruvimbo/bureau_balance.csv\")\n",
    "#bureau_balance.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27299925 entries, 0 to 27299924\n",
      "Data columns (total 3 columns):\n",
      "SK_ID_BUREAU      int64\n",
      "MONTHS_BALANCE    int64\n",
      "STATUS            object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 624.8+ MB\n"
     ]
    }
   ],
   "source": [
    "bureau_balance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bureau balance max is 0 as debts are recorded as negative number , the min taken insted to represent the maximum loan advanced to a client \n",
    "bureau_balance_grouped = bureau_balance.drop(['STATUS'], axis= 1).groupby('SK_ID_BUREAU', as_index = False).agg(['count', 'mean', 'max','min', 'sum']).reset_index()\n",
    "#bureau_balance_grouped.head()\n",
    "bureau_balance_grouped.name= 'bureau_balance_grouped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['SK_ID_BUREAU']\n",
    "\n",
    "# Iterate through the variables names\n",
    "for var in bureau_balance_grouped.columns.levels[0]:\n",
    "    # Skip the id name\n",
    "    if var != 'SK_ID_BUREAU':\n",
    "        \n",
    "        # Iterate through the stat names\n",
    "        for stat in bureau_balance_grouped.columns.levels[1][:-1]:\n",
    "            # Make a new column name for the variable and stat\n",
    "            columns.append('bureau_balance_%s_%s' % (var, stat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "bureau_balance_grouped.columns = columns\n",
    "#bureau_balance_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id_lookup= bureau [['SK_ID_BUREAU','SK_ID_CURR']]\n",
    "#customer_id_lookup.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance_grouped = pd.merge(bureau_balance_grouped, customer_id_lookup, how='left',left_on='SK_ID_BUREAU', right_on='SK_ID_BUREAU')\n",
    "#bureau_balance_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bureau_balance_customer = bureau_balance_grouped.drop(['SK_ID_BUREAU'],axis=1).groupby('SK_ID_CURR', as_index = False).agg(['mean', 'max', 'sum']).reset_index()\n",
    "#bureau_balance_customer.head()\n",
    "bureau_balance_customer.name='bureau_balance_customer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns= format_columns(bureau_balance_customer)\n",
    "bureau_balance_customer.columns= columns\n",
    "#bureau_balance_customer.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_CASH_balance = pd.read_csv(\"//home/mgwarada/Desktop/Ruvimbo/POS_CASH_balance.csv\")\n",
    "#POS_CASH_balance.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10001358 entries, 0 to 10001357\n",
      "Data columns (total 8 columns):\n",
      "SK_ID_PREV               int64\n",
      "SK_ID_CURR               int64\n",
      "MONTHS_BALANCE           int64\n",
      "CNT_INSTALMENT           float64\n",
      "CNT_INSTALMENT_FUTURE    float64\n",
      "NAME_CONTRACT_STATUS     object\n",
      "SK_DPD                   int64\n",
      "SK_DPD_DEF               int64\n",
      "dtypes: float64(2), int64(5), object(1)\n",
      "memory usage: 610.4+ MB\n"
     ]
    }
   ],
   "source": [
    "POS_CASH_balance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bureau balance max is 0 as debts are recorded as negative number , the min taken insted to represent the maximum loan advanced to a client \n",
    "POS_CASH_grouped = POS_CASH_balance.drop(['SK_ID_PREV'],axis=1).groupby('SK_ID_CURR', as_index = False).agg([ 'mean', 'max', 'sum']).reset_index()\n",
    "POS_CASH_grouped.name= 'POS_CASH_grouped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns= format_columns(POS_CASH_grouped)\n",
    "POS_CASH_grouped.columns= columns\n",
    "#POS_CASH_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_balance = pd.read_csv(\"/home/mgwarada/Desktop/Ruvimbo/credit_card_balance.csv\")\n",
    "#credit_card_balance.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3840312 entries, 0 to 3840311\n",
      "Data columns (total 23 columns):\n",
      "SK_ID_PREV                    int64\n",
      "SK_ID_CURR                    int64\n",
      "MONTHS_BALANCE                int64\n",
      "AMT_BALANCE                   float64\n",
      "AMT_CREDIT_LIMIT_ACTUAL       int64\n",
      "AMT_DRAWINGS_ATM_CURRENT      float64\n",
      "AMT_DRAWINGS_CURRENT          float64\n",
      "AMT_DRAWINGS_OTHER_CURRENT    float64\n",
      "AMT_DRAWINGS_POS_CURRENT      float64\n",
      "AMT_INST_MIN_REGULARITY       float64\n",
      "AMT_PAYMENT_CURRENT           float64\n",
      "AMT_PAYMENT_TOTAL_CURRENT     float64\n",
      "AMT_RECEIVABLE_PRINCIPAL      float64\n",
      "AMT_RECIVABLE                 float64\n",
      "AMT_TOTAL_RECEIVABLE          float64\n",
      "CNT_DRAWINGS_ATM_CURRENT      float64\n",
      "CNT_DRAWINGS_CURRENT          int64\n",
      "CNT_DRAWINGS_OTHER_CURRENT    float64\n",
      "CNT_DRAWINGS_POS_CURRENT      float64\n",
      "CNT_INSTALMENT_MATURE_CUM     float64\n",
      "NAME_CONTRACT_STATUS          object\n",
      "SK_DPD                        int64\n",
      "SK_DPD_DEF                    int64\n",
      "dtypes: float64(15), int64(7), object(1)\n",
      "memory usage: 673.9+ MB\n"
     ]
    }
   ],
   "source": [
    "credit_card_balance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_balance_grouped = credit_card_balance.drop( ['SK_ID_PREV'], axis =1).groupby('SK_ID_CURR', as_index = False).agg(['mean', 'max', 'sum']).reset_index()\n",
    "credit_card_balance_grouped.name= 'credit_card_balance_grouped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = format_columns(credit_card_balance_grouped)\n",
    "credit_card_balance_grouped.columns= columns \n",
    "#credit_card_balance_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_application = pd.read_csv(\"//home/mgwarada/Desktop/Ruvimbo/previous_application.csv\")\n",
    "#previous_application.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1670214 entries, 0 to 1670213\n",
      "Data columns (total 37 columns):\n",
      "SK_ID_PREV                     1670214 non-null int64\n",
      "SK_ID_CURR                     1670214 non-null int64\n",
      "NAME_CONTRACT_TYPE             1670214 non-null object\n",
      "AMT_ANNUITY                    1297979 non-null float64\n",
      "AMT_APPLICATION                1670214 non-null float64\n",
      "AMT_CREDIT                     1670213 non-null float64\n",
      "AMT_DOWN_PAYMENT               774370 non-null float64\n",
      "AMT_GOODS_PRICE                1284699 non-null float64\n",
      "WEEKDAY_APPR_PROCESS_START     1670214 non-null object\n",
      "HOUR_APPR_PROCESS_START        1670214 non-null int64\n",
      "FLAG_LAST_APPL_PER_CONTRACT    1670214 non-null object\n",
      "NFLAG_LAST_APPL_IN_DAY         1670214 non-null int64\n",
      "RATE_DOWN_PAYMENT              774370 non-null float64\n",
      "RATE_INTEREST_PRIMARY          5951 non-null float64\n",
      "RATE_INTEREST_PRIVILEGED       5951 non-null float64\n",
      "NAME_CASH_LOAN_PURPOSE         1670214 non-null object\n",
      "NAME_CONTRACT_STATUS           1670214 non-null object\n",
      "DAYS_DECISION                  1670214 non-null int64\n",
      "NAME_PAYMENT_TYPE              1670214 non-null object\n",
      "CODE_REJECT_REASON             1670214 non-null object\n",
      "NAME_TYPE_SUITE                849809 non-null object\n",
      "NAME_CLIENT_TYPE               1670214 non-null object\n",
      "NAME_GOODS_CATEGORY            1670214 non-null object\n",
      "NAME_PORTFOLIO                 1670214 non-null object\n",
      "NAME_PRODUCT_TYPE              1670214 non-null object\n",
      "CHANNEL_TYPE                   1670214 non-null object\n",
      "SELLERPLACE_AREA               1670214 non-null int64\n",
      "NAME_SELLER_INDUSTRY           1670214 non-null object\n",
      "CNT_PAYMENT                    1297984 non-null float64\n",
      "NAME_YIELD_GROUP               1670214 non-null object\n",
      "PRODUCT_COMBINATION            1669868 non-null object\n",
      "DAYS_FIRST_DRAWING             997149 non-null float64\n",
      "DAYS_FIRST_DUE                 997149 non-null float64\n",
      "DAYS_LAST_DUE_1ST_VERSION      997149 non-null float64\n",
      "DAYS_LAST_DUE                  997149 non-null float64\n",
      "DAYS_TERMINATION               997149 non-null float64\n",
      "NFLAG_INSURED_ON_APPROVAL      997149 non-null float64\n",
      "dtypes: float64(15), int64(6), object(16)\n",
      "memory usage: 471.5+ MB\n"
     ]
    }
   ],
   "source": [
    "previous_application.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_application_grouped = previous_application.drop(['SK_ID_PREV'],axis=1).groupby('SK_ID_CURR', as_index = False).agg([ 'mean', 'max', 'sum']).reset_index()\n",
    "previous_application_grouped.name= 'previous_application_grouped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = format_columns(previous_application_grouped)\n",
    "previous_application_grouped.columns= columns\n",
    "#previous_application_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments_payments = pd.read_csv(\"/home/mgwarada/Desktop/Ruvimbo/installments_payments.csv\")\n",
    "#installments_payments.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13605401 entries, 0 to 13605400\n",
      "Data columns (total 8 columns):\n",
      "SK_ID_PREV                int64\n",
      "SK_ID_CURR                int64\n",
      "NUM_INSTALMENT_VERSION    float64\n",
      "NUM_INSTALMENT_NUMBER     int64\n",
      "DAYS_INSTALMENT           float64\n",
      "DAYS_ENTRY_PAYMENT        float64\n",
      "AMT_INSTALMENT            float64\n",
      "AMT_PAYMENT               float64\n",
      "dtypes: float64(5), int64(3)\n",
      "memory usage: 830.4 MB\n"
     ]
    }
   ],
   "source": [
    "installments_payments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "installments_payments_grouped = installments_payments.drop( ['SK_ID_PREV'],axis=1 ).groupby('SK_ID_CURR', as_index = False).agg(['mean', 'max', 'sum']).reset_index()\n",
    "installments_payments_grouped.name ='installments_payments_grouped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = format_columns(installments_payments_grouped)\n",
    "installments_payments_grouped.columns = columns \n",
    "#installments_payments_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#free up memory\n",
    "del credit_card_balance\n",
    "del POS_CASH_balance\n",
    "del previous_application\n",
    "del bureau_balance\n",
    "del bureau\n",
    "del installments_payments \n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 336)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  #merging datasets DO NOT DELETE\n",
    "train_data_v0 = application_train.merge(bureau_grouped, on= 'SK_ID_CURR',how='left').merge(credit_card_balance_grouped, on= 'SK_ID_CURR',how='left').merge(installments_payments_grouped,on = 'SK_ID_CURR',how='left').merge(POS_CASH_grouped, on ='SK_ID_CURR',how='left').merge(previous_application_grouped,on ='SK_ID_CURR',how='left').merge(bureau_balance_customer, on = 'SK_ID_CURR',how='left')\n",
    "train_data_v0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_v1 =train_data_v0\n",
    "#train_data_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features: 17\n",
      "Number of numerical features: 320\n"
     ]
    }
   ],
   "source": [
    "categorical_list = ['SK_ID_CURR']\n",
    "numerical_list = []\n",
    "for i in train_data_v1.columns.tolist():\n",
    "    if train_data_v1[i].dtype=='object':\n",
    "        categorical_list.append(i)\n",
    "    else:\n",
    "        numerical_list.append(i)\n",
    "print('Number of categorical features:', str(len(categorical_list)))\n",
    "print('Number of numerical features:', str(len(numerical_list)))\n",
    "#numerical_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_train = train_data_v1 [numerical_list]\n",
    "#numeric_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_train = train_data_v1 [categorical_list]\n",
    "#categorical_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgwarada/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgwarada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 columns were label encoded.\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in categorical_train:\n",
    "    if categorical_train[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(categorical_train[col].unique())) <= 2:\n",
    "            # Train on the training data\n",
    "            le.fit(categorical_train[col])\n",
    "            # Transform both training and testing data\n",
    "            categorical_train[col] = le.transform(categorical_train[col])\n",
    "            \n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "            \n",
    "print('%d columns were label encoded.' % le_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummies for categorical data\n",
    "categorical = pd.get_dummies(categorical_train.select_dtypes('object'))\n",
    "categorical['SK_ID_CURR'] = categorical_train['SK_ID_CURR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_grouped = categorical.groupby('SK_ID_CURR',as_index = False).agg(['count', 'mean'])\n",
    "categorical_grouped.name = 'categorical_grouped'\n",
    "#categorical_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of column names\n",
    "columnsc = []\n",
    "\n",
    "# Iterate through the variables names\n",
    "for var in categorical_grouped.columns.levels[0]:\n",
    "    # Skip the id name\n",
    "    if var != 'SK_ID_CURR':\n",
    "        \n",
    "        # Iterate through the stat names\n",
    "        for stat in categorical_grouped.columns.levels[1][:]:\n",
    "            # Make a new column name for the variable and stat\n",
    "            columnsc.append('categorical_grouped_%s_%s' % (var, stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = format_columns(categorical_grouped)\n",
    "categorical_grouped.columns= columnsc\n",
    "#categorical_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#calculate missing values for each column\n",
    "cat_percent_missing = (categorical_grouped.isnull().sum(axis = 0)/len(categorical_grouped ))*100\n",
    "#round(abs(cat_percent_missing),1).sort_values(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_percent_missing = abs((numeric_train.isnull().sum(axis = 0)/len(numeric_train))*100)\n",
    "#num_percent_missing.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_percent_missing = num_percent_missing.index[num_percent_missing> 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove variables with more than 75% of data missing\n",
    "numeric_train = numeric_train.drop(columns = num_percent_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>...</th>\n",
       "      <th>categorical_grouped_WALLSMATERIAL_MODE_Panel_count</th>\n",
       "      <th>categorical_grouped_WALLSMATERIAL_MODE_Panel_mean</th>\n",
       "      <th>categorical_grouped_WALLSMATERIAL_MODE_Stone, brick_count</th>\n",
       "      <th>categorical_grouped_WALLSMATERIAL_MODE_Stone, brick_mean</th>\n",
       "      <th>categorical_grouped_WALLSMATERIAL_MODE_Wooden_count</th>\n",
       "      <th>categorical_grouped_WALLSMATERIAL_MODE_Wooden_mean</th>\n",
       "      <th>categorical_grouped_EMERGENCYSTATE_MODE_No_count</th>\n",
       "      <th>categorical_grouped_EMERGENCYSTATE_MODE_No_mean</th>\n",
       "      <th>categorical_grouped_EMERGENCYSTATE_MODE_Yes_count</th>\n",
       "      <th>categorical_grouped_EMERGENCYSTATE_MODE_Yes_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-19005</td>\n",
       "      <td>-3039</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 323 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "0      100002       1             0          202500.0    406597.5   \n",
       "1      100003       0             0          270000.0   1293502.5   \n",
       "2      100004       0             0           67500.0    135000.0   \n",
       "3      100006       0             0          135000.0    312682.5   \n",
       "4      100007       0             0          121500.0    513000.0   \n",
       "\n",
       "   AMT_ANNUITY  AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "0      24700.5         351000.0                    0.018801       -9461   \n",
       "1      35698.5        1129500.0                    0.003541      -16765   \n",
       "2       6750.0         135000.0                    0.010032      -19046   \n",
       "3      29686.5         297000.0                    0.008019      -19005   \n",
       "4      21865.5         513000.0                    0.028663      -19932   \n",
       "\n",
       "   DAYS_EMPLOYED                        ...                         \\\n",
       "0           -637                        ...                          \n",
       "1          -1188                        ...                          \n",
       "2           -225                        ...                          \n",
       "3          -3039                        ...                          \n",
       "4          -3038                        ...                          \n",
       "\n",
       "   categorical_grouped_WALLSMATERIAL_MODE_Panel_count  \\\n",
       "0                                                  1    \n",
       "1                                                  1    \n",
       "2                                                  1    \n",
       "3                                                  1    \n",
       "4                                                  1    \n",
       "\n",
       "   categorical_grouped_WALLSMATERIAL_MODE_Panel_mean  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "   categorical_grouped_WALLSMATERIAL_MODE_Stone, brick_count  \\\n",
       "0                                                  1           \n",
       "1                                                  1           \n",
       "2                                                  1           \n",
       "3                                                  1           \n",
       "4                                                  1           \n",
       "\n",
       "   categorical_grouped_WALLSMATERIAL_MODE_Stone, brick_mean  \\\n",
       "0                                                  1          \n",
       "1                                                  0          \n",
       "2                                                  0          \n",
       "3                                                  0          \n",
       "4                                                  0          \n",
       "\n",
       "   categorical_grouped_WALLSMATERIAL_MODE_Wooden_count  \\\n",
       "0                                                  1     \n",
       "1                                                  1     \n",
       "2                                                  1     \n",
       "3                                                  1     \n",
       "4                                                  1     \n",
       "\n",
       "   categorical_grouped_WALLSMATERIAL_MODE_Wooden_mean  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  0    \n",
       "\n",
       "   categorical_grouped_EMERGENCYSTATE_MODE_No_count  \\\n",
       "0                                                 1   \n",
       "1                                                 1   \n",
       "2                                                 1   \n",
       "3                                                 1   \n",
       "4                                                 1   \n",
       "\n",
       "   categorical_grouped_EMERGENCYSTATE_MODE_No_mean  \\\n",
       "0                                                1   \n",
       "1                                                1   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "   categorical_grouped_EMERGENCYSTATE_MODE_Yes_count  \\\n",
       "0                                                  1   \n",
       "1                                                  1   \n",
       "2                                                  1   \n",
       "3                                                  1   \n",
       "4                                                  1   \n",
       "\n",
       "   categorical_grouped_EMERGENCYSTATE_MODE_Yes_mean  \n",
       "0                                                 0  \n",
       "1                                                 0  \n",
       "2                                                 0  \n",
       "3                                                 0  \n",
       "4                                                 0  \n",
       "\n",
       "[5 rows x 323 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_v1 = numeric_train.merge(categorical_grouped, left_on = 'SK_ID_CURR', right_index = True, how = 'left')\n",
    "train_data_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#free up memory\n",
    "#del categorical_grouped\n",
    "del bureau_grouped\n",
    "del bureau_balance_grouped\n",
    "del installments_payments_grouped\n",
    "del credit_card_balance_grouped\n",
    "del previous_application_grouped\n",
    "del POS_CASH_grouped\n",
    "del num_percent_missing\n",
    "del cat_percent_missing\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= train_data_v1.drop(['SK_ID_CURR','TARGET'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify multicolinearity\n",
    "threshold = 0.8\n",
    "\n",
    "# Absolute value correlation matrix\n",
    "corr_matrix = train.corr().abs()\n",
    "#corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "#upper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track columns to remove and columns already examined\n",
    "cols_to_remove = []\n",
    "cols_seen = []\n",
    "cols_to_remove_pair = []\n",
    "\n",
    "# Iterate through columns and correlated columns\n",
    "for key, value in above_threshold_vars.items():\n",
    "    # Keep track of columns already examined\n",
    "    cols_seen.append(key)\n",
    "    for x in value:\n",
    "        if x == key:\n",
    "            next\n",
    "        else:\n",
    "            # Only want to remove one in a pair\n",
    "            if x not in cols_seen:\n",
    "                cols_to_remove.append(x)\n",
    "                cols_to_remove_pair.append(key)\n",
    "            \n",
    "cols_to_remove = list(set(cols_to_remove))\n",
    "print('Number of columns to remove: ', len(cols_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 columns to remove.\n"
     ]
    }
   ],
   "source": [
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "print('There are %d columns to remove.' % (len(to_drop)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#free up memory\n",
    "del corr_matrix\n",
    "del upper\n",
    "del to_drop\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " #train_data_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = train_data_v1['TARGET']\n",
    "feature_name = train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#del numeric_train\n",
    "#del categorical_train\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.fillna(train.median()).head()\n",
    "train = train.fillna(train.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_selector(X, y):\n",
    "    cor_list = []\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-100:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgwarada/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2400: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/mgwarada/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2401: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 selected features\n"
     ]
    }
   ],
   "source": [
    "#feature selection\n",
    "cor_support, cor_feature = cor_selector(train,response)\n",
    "print(str(len(cor_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgwarada/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm = MinMaxScaler().fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 298 features.\n",
      "Fitting estimator with 288 features.\n",
      "Fitting estimator with 278 features.\n",
      "Fitting estimator with 268 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 108 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "  n_features_to_select=100, step=10, verbose=5)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrapper method using regression see RFE: http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
    "\n",
    "rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=100, step=10, verbose=5)\n",
    "rfe_selector.fit(train_norm, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 selected features\n"
     ]
    }
   ],
   "source": [
    "rfe_support = rfe_selector.get_support()\n",
    "rfe_feature = train.loc[:,rfe_support].columns.tolist()\n",
    "print(str(len(rfe_feature)), 'selected features')\n",
    "#rfe_feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfe_support  = 308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold='1.25*median')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(train, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 selected features\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = train.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str(len(embeded_rf_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=100, score_func=<function chi2 at 0x7f8073acb488>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chi_selector = SelectKBest(chi2, k=100)\n",
    "chi_selector.fit(train_norm, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 selected features\n"
     ]
    }
   ],
   "source": [
    "chi_support = chi_selector.get_support()\n",
    "chi_feature = train.loc[:,chi_support].columns.tolist()\n",
    "print(str(len(chi_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original= pd.DataFrame({'Feature':feature_name[2:]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_0 =  pd.DataFrame({'Chi-square': chi_support,\n",
    "                             'Random Forest':embeded_rf_support})   \n",
    "additional_1= pd.DataFrame({'Pearson_corr':cor_support})\n",
    "additional_2= pd.DataFrame({'Logistic':rfe_support})\n",
    "original_1 = pd.concat([original,additional_0], axis =1)\n",
    "original_2 = pd.concat([original_1,additional_1], axis =1)\n",
    "original_3 =pd.concat([original_2,additional_2], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_df = original_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_selection_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del additional_1\n",
    "del additional_2\n",
    "del original_2 \n",
    "del original_3 \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_df['Total']=0\n",
    "feature_selection_df['Total']=np.sum(feature_selection_df==True, axis=1)\n",
    "# display the top 100\n",
    "feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\n",
    "feature_selection_df.index = range(1, len(feature_selection_df)+1)\n",
    "#feature_selection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = feature_selection_df[feature_selection_df['Total']==4]\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del feature_selection_df \n",
    "del chi_support\n",
    "del chi_feature\n",
    "del embeded_rf_support\n",
    "del embeded_rf_feature\n",
    "del rfe_selector\n",
    "del rfe_feature\n",
    "del cor_support\n",
    "del cor_feature\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgwarada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/mgwarada/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:915: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc[key] = value\n",
      "/home/mgwarada/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2961: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/mgwarada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "features_f = features['Feature']\n",
    "features_f[55] = 'SK_ID_CURR'\n",
    "features_f[56] = 'TARGET'\n",
    "#features_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_v1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-72476983aa42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data_final\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_v1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#del train_data_final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data_v1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data_final  = train_data_v1[features_f]\n",
    "#del train_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_response = train_data_final.TARGET\n",
    "train_dataset =  train_data_final.drop(columns=['TARGET','SK_ID_CURR'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = train_dataset.fillna(train_dataset.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize/scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit only to the training data\n",
    "scaler.fit(train_dataset)\n",
    "train_dataset = scaler.transform(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.neural_network'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-18d77bd528a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.neural_network'"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30,max_iter =500))\n",
    "mlp.fit(train_dataset,train_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit random forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "                           \n",
    "                           \n",
    "randomForestModel = RandomForestClassifier(max_depth=5,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForestModel.fit(train_dataset,train_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.15021649e-04 6.64213315e-05 5.15869563e-04 9.16050806e-04\n",
      " 4.70801633e-04 2.16066861e-04 0.00000000e+00 6.15245077e-04\n",
      " 3.38345153e-02 9.00368219e-04 9.94993033e-05 0.00000000e+00\n",
      " 3.03069607e-04 4.16258402e-04 0.00000000e+00 0.00000000e+00\n",
      " 1.11612103e-03 2.24387244e-03 1.60523998e-04 1.01726256e-02\n",
      " 2.30072279e-05 6.11243056e-04 8.93653352e-03 0.00000000e+00\n",
      " 7.94371519e-04 6.09525969e-03 6.10136026e-03 1.04486121e-04\n",
      " 4.64825358e-05 0.00000000e+00 7.48766314e-04 7.37704429e-03\n",
      " 7.71343656e-04 0.00000000e+00 1.35663834e-04 0.00000000e+00\n",
      " 1.15639192e-03 9.23467025e-02 1.32001055e-02 0.00000000e+00\n",
      " 4.02766329e-03 2.20041059e-03 7.35431837e-02 2.01645526e-03\n",
      " 3.01373265e-04 2.39797164e-04 2.78779469e-03 5.99245660e-04\n",
      " 0.00000000e+00 4.75955377e-01 2.99675983e-02 4.78301011e-02\n",
      " 8.85715986e-02 8.10483084e-02]\n"
     ]
    }
   ],
   "source": [
    " print(randomForestModel.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_roc_auc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-b32e3ed70347>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrandomForestModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_score_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_roc_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_roc_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_score_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_roc_auc' is not defined"
     ]
    }
   ],
   "source": [
    "#K-Fold cross validation\n",
    "cv = StratifiedKFold(n_splits=10, random_state=123, shuffle=True)\n",
    "results = pd.DataFrame(columns=['training_score', 'test_score'])\n",
    "fprs, tprs, scores = [], [], []\n",
    "    \n",
    "for (train, test), i in zip(cv.split(train_dataset,train_response), range(10)):\n",
    "    randomForestModel.fit(train_dataset.iloc[train], train_response.iloc[train])\n",
    "    _, _, auc_score_train = compute_roc_auc(train)\n",
    "    fpr, tpr, auc_score = compute_roc_auc(test)\n",
    "    scores.append((auc_score_train, auc_score))\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "\n",
    "plot_roc_curve(fprs, tprs);\n",
    "pd.DataFrame(scores, columns=['AUC Train', 'AUC Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit chaid analysis\n",
    "#from CHAID import Tree\n",
    "from modshogun import PT_MULTICLASS, CHAIDTree\n",
    "from numpy import array, dtype, int32\n",
    "\n",
    "tree = Tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit neural network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit logistic regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Make the model with the specified regularization parameter\n",
    "log_reg = LogisticRegression(C = 0.0001)\n",
    "\n",
    "# Train on the training data\n",
    "log_reg.fit(train_dataset, train_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN classifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model usinfit(X_train, y_train)g the training sets\n",
    "model.fit(features,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratified k fold cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
    "# X is the feature set and y is the target\n",
    "for train_index, test_index in skf.split(X,y): \n",
    "    print(\"Train:\", train_index, \"Validation:\", val_index) \n",
    "    X_train, X_test = X[train_index], X[val_index] \n",
    "    y_train, y_test = y[train_index], y[val_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC AUC\n",
    "\n",
    ">>> import numpy as np\n",
    ">>> from sklearn import metrics\n",
    ">>> y = np.array([1, 1, 2, 2])\n",
    ">>> pred = np.array([0.1, 0.4, 0.35, 0.8])\n",
    ">>> fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)\n",
    ">>> metrics.auc(fpr, tpr)\n",
    "0.75"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
